{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal to the model isn't allowing for improved experimentation results. I'm testing the possibility of improvement through the application of feature engineering. This is counter intuitive to what I've learnd in the past about deep neural networks beause they offer a natrual feature engineering behavior thorugh layers, nodes and activation functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, initializers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.losses import BinaryFocalCrossentropy\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score, roc_auc_score, average_precision_score,\n",
    "    classification_report, multilabel_confusion_matrix,precision_recall_curve\n",
    ")\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit as MLSSS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import optuna\n",
    "from optuna.visualization import (\n",
    "    plot_optimization_history, plot_param_importances, plot_slice\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from pyprojroot import here\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 17 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   quality_variation        10000 non-null  int64  \n",
      " 1   Air temperature [K]      10000 non-null  float64\n",
      " 2   Process temperature [K]  10000 non-null  float64\n",
      " 3   Rotational speed [rpm]   10000 non-null  float64\n",
      " 4   Torque [Nm]              10000 non-null  float64\n",
      " 5   Tool wear [min]          10000 non-null  float64\n",
      " 6   TWF                      10000 non-null  int64  \n",
      " 7   HDF                      10000 non-null  int64  \n",
      " 8   PWF                      10000 non-null  int64  \n",
      " 9   OSF                      10000 non-null  int64  \n",
      " 10  RNF                      10000 non-null  int64  \n",
      " 11  joint_PWF_OSF            10000 non-null  int64  \n",
      " 12  joint_TWF_RNF            10000 non-null  int64  \n",
      " 13  joint_HDF_PWF            10000 non-null  int64  \n",
      " 14  joint_HDF_OSF            10000 non-null  int64  \n",
      " 15  joint_TWF_OSF            10000 non-null  int64  \n",
      " 16  joint_TWF_PWF_OSF        10000 non-null  int64  \n",
      "dtypes: float64(5), int64(12)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "multi_label_data = pd.read_csv(here('data/processed/joint_target_vectors_df.csv'))\n",
    "multi_label_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF', 'joint_PWF_OSF',\n",
    "            'joint_TWF_RNF', 'joint_HDF_PWF', 'joint_HDF_OSF',\n",
    "            'joint_TWF_OSF', 'joint_TWF_PWF_OSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_label_data['Toolwear*Torque'] = multi_label_data['Tool wear [min]'] * multi_label_data['Torque [Nm]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_label_data['Toolwear-Strain'] = multi_label_data['Process temperature [K]'] - multi_label_data['Air temperature [K]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_label_data['TorquetimesInvRPM'] = multi_label_data['Torque [Nm]'] * (1 / multi_label_data['Rotational speed [rpm]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_label_data['Toolwear*AirTemp'] = multi_label_data['Tool wear [min]'] * (multi_label_data['Air temperature [K]'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 21 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   quality_variation        10000 non-null  int64  \n",
      " 1   Air temperature [K]      10000 non-null  float64\n",
      " 2   Process temperature [K]  10000 non-null  float64\n",
      " 3   Rotational speed [rpm]   10000 non-null  float64\n",
      " 4   Torque [Nm]              10000 non-null  float64\n",
      " 5   Tool wear [min]          10000 non-null  float64\n",
      " 6   TWF                      10000 non-null  int64  \n",
      " 7   HDF                      10000 non-null  int64  \n",
      " 8   PWF                      10000 non-null  int64  \n",
      " 9   OSF                      10000 non-null  int64  \n",
      " 10  RNF                      10000 non-null  int64  \n",
      " 11  joint_PWF_OSF            10000 non-null  int64  \n",
      " 12  joint_TWF_RNF            10000 non-null  int64  \n",
      " 13  joint_HDF_PWF            10000 non-null  int64  \n",
      " 14  joint_HDF_OSF            10000 non-null  int64  \n",
      " 15  joint_TWF_OSF            10000 non-null  int64  \n",
      " 16  joint_TWF_PWF_OSF        10000 non-null  int64  \n",
      " 17  Toolwear*Torque          10000 non-null  float64\n",
      " 18  Toolwear-Strain          10000 non-null  float64\n",
      " 19  TorquetimesInvRPM        10000 non-null  float64\n",
      " 20  Toolwear*AirTemp         10000 non-null  float64\n",
      "dtypes: float64(9), int64(12)\n",
      "memory usage: 1.6 MB\n"
     ]
    }
   ],
   "source": [
    "multi_label_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality_variation</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>...</th>\n",
       "      <th>joint_PWF_OSF</th>\n",
       "      <th>joint_TWF_RNF</th>\n",
       "      <th>joint_HDF_PWF</th>\n",
       "      <th>joint_HDF_OSF</th>\n",
       "      <th>joint_TWF_OSF</th>\n",
       "      <th>joint_TWF_PWF_OSF</th>\n",
       "      <th>Toolwear*Torque</th>\n",
       "      <th>Toolwear-Strain</th>\n",
       "      <th>TorquetimesInvRPM</th>\n",
       "      <th>Toolwear*AirTemp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.952389</td>\n",
       "      <td>-0.947360</td>\n",
       "      <td>0.068185</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>-1.695984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.478606</td>\n",
       "      <td>0.005030</td>\n",
       "      <td>4.138728</td>\n",
       "      <td>1.615237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.902393</td>\n",
       "      <td>-0.879959</td>\n",
       "      <td>-0.729472</td>\n",
       "      <td>0.633308</td>\n",
       "      <td>-1.648852</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.044231</td>\n",
       "      <td>0.022434</td>\n",
       "      <td>-0.868174</td>\n",
       "      <td>1.487913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.952389</td>\n",
       "      <td>-1.014761</td>\n",
       "      <td>-0.227450</td>\n",
       "      <td>0.944290</td>\n",
       "      <td>-1.617430</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.527323</td>\n",
       "      <td>-0.062371</td>\n",
       "      <td>-4.151639</td>\n",
       "      <td>1.540424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.902393</td>\n",
       "      <td>-0.947360</td>\n",
       "      <td>-0.590021</td>\n",
       "      <td>-0.048845</td>\n",
       "      <td>-1.586009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.077469</td>\n",
       "      <td>-0.044966</td>\n",
       "      <td>0.082785</td>\n",
       "      <td>1.431204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.902393</td>\n",
       "      <td>-0.879959</td>\n",
       "      <td>-0.729472</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>-1.554588</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.002041</td>\n",
       "      <td>0.022434</td>\n",
       "      <td>-0.001800</td>\n",
       "      <td>1.402850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   quality_variation  Air temperature [K]  Process temperature [K]  \\\n",
       "0                  1            -0.952389                -0.947360   \n",
       "1                  0            -0.902393                -0.879959   \n",
       "2                  0            -0.952389                -1.014761   \n",
       "3                  0            -0.902393                -0.947360   \n",
       "4                  0            -0.902393                -0.879959   \n",
       "\n",
       "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  TWF  HDF  PWF  OSF  \\\n",
       "0                0.068185     0.282200        -1.695984    0    0    0    0   \n",
       "1               -0.729472     0.633308        -1.648852    0    0    0    0   \n",
       "2               -0.227450     0.944290        -1.617430    0    0    0    0   \n",
       "3               -0.590021    -0.048845        -1.586009    0    0    0    0   \n",
       "4               -0.729472     0.001313        -1.554588    0    0    0    0   \n",
       "\n",
       "   ...  joint_PWF_OSF  joint_TWF_RNF  joint_HDF_PWF  joint_HDF_OSF  \\\n",
       "0  ...              0              0              0              0   \n",
       "1  ...              0              0              0              0   \n",
       "2  ...              0              0              0              0   \n",
       "3  ...              0              0              0              0   \n",
       "4  ...              0              0              0              0   \n",
       "\n",
       "   joint_TWF_OSF  joint_TWF_PWF_OSF  Toolwear*Torque  Toolwear-Strain  \\\n",
       "0              0                  0        -0.478606         0.005030   \n",
       "1              0                  0        -1.044231         0.022434   \n",
       "2              0                  0        -1.527323        -0.062371   \n",
       "3              0                  0         0.077469        -0.044966   \n",
       "4              0                  0        -0.002041         0.022434   \n",
       "\n",
       "   TorquetimesInvRPM  Toolwear*AirTemp  \n",
       "0           4.138728          1.615237  \n",
       "1          -0.868174          1.487913  \n",
       "2          -4.151639          1.540424  \n",
       "3           0.082785          1.431204  \n",
       "4          -0.001800          1.402850  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'n_layers': 6, 'gamma': 0.9003549934636083, 'units_l0': 577, 'units_l1': 184, 'units_l2': 214, 'units_l3': 206, 'units_l4': 801, 'lr': 2.8746290296601193e-05, 'epochs': 97, 'beta_1': 0.8963081622002852, 'beta_2': 0.9366159181660023, 'epsilon': 8.562431439031271e-07, 'alpha_pow': 0.9534631280825616}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Quick train/val split (stratify on \"any failure\" just to be sane) ----\n",
    "y_any = (multi_label_data[targets].sum(axis=1) > 0).astype(int)\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    multi_label_data,\n",
    "    test_size=0.2,\n",
    "    random_state=23,\n",
    "    stratify=y_any\n",
    ")\n",
    "\n",
    "# ---- Scale numeric features (train stats only) ----\n",
    "num_cols = [\n",
    "    'Tool wear [min]',\n",
    "    'Torque [Nm]',\n",
    "    'Rotational speed [rpm]',\n",
    "    'Air temperature [K]',\n",
    "    'Process temperature [K]',\n",
    "    'Toolwear*Torque',\n",
    "    'Toolwear-Strain',\n",
    "    'TorquetimesInvRPM',\n",
    "    'Toolwear*AirTemp',\n",
    "]\n",
    "\n",
    "\n",
    "train_df[num_cols] = train_df[num_cols]\n",
    "val_df[num_cols]   = val_df[num_cols]\n",
    "\n",
    "y_train = train_df[targets].values.astype('float64')\n",
    "y_val   = val_df[targets].values.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hidden_layer_sizes=None, bias_init_value=None):\n",
    "    if hidden_layer_sizes is None:\n",
    "        hidden_layer_sizes = []\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(23)\n",
    "\n",
    "    # --- Inputs ---\n",
    "    toolWear = tf.keras.layers.Input(shape=(1,), dtype=tf.float64, name='Tool wear [min]')\n",
    "    torque   = tf.keras.layers.Input(shape=(1,), dtype=tf.float64, name='Torque [Nm]')\n",
    "    rotationalSpeed = tf.keras.layers.Input(shape=(1,), dtype=tf.float64, name='Rotational speed [rpm]')\n",
    "    qualityVariation = tf.keras.layers.Input(shape=(1,), dtype=tf.int64,  name='quality_variation')\n",
    "    airTemperature = tf.keras.layers.Input(shape=(1,), dtype=tf.float64, name='Air temperature [K]')\n",
    "    processTemperature = tf.keras.layers.Input(shape=(1,), dtype=tf.float64, name='Process temperature [K]')\n",
    "\n",
    "    # NEW engineered-feature inputs\n",
    "    toolwear_torque  = tf.keras.layers.Input(shape=(1,), dtype=tf.float64, name='Toolwear*Torque')\n",
    "    toolwear_strain  = tf.keras.layers.Input(shape=(1,), dtype=tf.float64, name='Toolwear-Strain')\n",
    "    torque_inv_rpm   = tf.keras.layers.Input(shape=(1,), dtype=tf.float64, name='TorquetimesInvRPM')\n",
    "    toolwear_airtemp = tf.keras.layers.Input(shape=(1,), dtype=tf.float64, name='Toolwear*AirTemp')\n",
    "\n",
    "    # Cast qualityVariation to float for Dense layers\n",
    "    qualityVariation_float = tf.keras.layers.Lambda(\n",
    "        lambda t: tf.cast(t, tf.float64),\n",
    "        name=\"quality_variation_to_float\"\n",
    "    )(qualityVariation)\n",
    "\n",
    "    # Concatenate all features\n",
    "    x = tf.keras.layers.Concatenate(name=\"feature_concat\")([\n",
    "        toolWear,\n",
    "        torque,\n",
    "        rotationalSpeed,\n",
    "        qualityVariation_float,\n",
    "        airTemperature,\n",
    "        processTemperature,\n",
    "        toolwear_torque,\n",
    "        toolwear_strain,\n",
    "        torque_inv_rpm,\n",
    "        toolwear_airtemp,\n",
    "    ])\n",
    "\n",
    "    # Hidden layers\n",
    "    for units in hidden_layer_sizes:\n",
    "        x = tf.keras.layers.Dense(units, activation='relu', dtype=tf.float64)(x)\n",
    "\n",
    "    # Bias initialization (we'll just use 0 here for this quick test)\n",
    "    if bias_init_value is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(bias_init_value)\n",
    "    else:\n",
    "        output_bias = tf.keras.initializers.Constant(0.0)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(\n",
    "        len(targets),\n",
    "        activation='sigmoid',\n",
    "        bias_initializer=output_bias,\n",
    "        dtype=tf.float64\n",
    "    )(x)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[\n",
    "            toolWear, torque, rotationalSpeed,\n",
    "            qualityVariation, airTemperature, processTemperature,\n",
    "            toolwear_torque, toolwear_strain, torque_inv_rpm, toolwear_airtemp\n",
    "        ],\n",
    "        outputs=outputs,\n",
    "        name=\"multilabel_failure_model\",\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def to_input_list(df):\n",
    "    \"\"\"Helper: convert df to list of model inputs in the correct order.\"\"\"\n",
    "    return [\n",
    "        df['Tool wear [min]'].values,\n",
    "        df['Torque [Nm]'].values,\n",
    "        df['Rotational speed [rpm]'].values,\n",
    "        df['quality_variation'].values,\n",
    "        df['Air temperature [K]'].values,\n",
    "        df['Process temperature [K]'].values,\n",
    "        df['Toolwear*Torque'].values,\n",
    "        df['Toolwear-Strain'].values,\n",
    "        df['TorquetimesInvRPM'].values,\n",
    "        df['Toolwear*AirTemp'].values,\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 6.8047e-07 - val_loss: 6.2692e-07\n",
      "Epoch 2/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5.8054e-07 - val_loss: 5.4761e-07\n",
      "Epoch 3/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5.1800e-07 - val_loss: 4.9501e-07\n",
      "Epoch 4/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 4.7586e-07 - val_loss: 4.5775e-07\n",
      "Epoch 5/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 4.4567e-07 - val_loss: 4.2994e-07\n",
      "Epoch 6/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 4.2276e-07 - val_loss: 4.0816e-07\n",
      "Epoch 7/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 4.0446e-07 - val_loss: 3.9051e-07\n",
      "Epoch 8/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 3.8929e-07 - val_loss: 3.7569e-07\n",
      "Epoch 9/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 3.7630e-07 - val_loss: 3.6298e-07\n",
      "Epoch 10/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 3.6492e-07 - val_loss: 3.5190e-07\n",
      "Epoch 11/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 3.5481e-07 - val_loss: 3.4207e-07\n",
      "Epoch 12/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 3.4564e-07 - val_loss: 3.3322e-07\n",
      "Epoch 13/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 3.3727e-07 - val_loss: 3.2509e-07\n",
      "Epoch 14/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 3.2950e-07 - val_loss: 3.1758e-07\n",
      "Epoch 15/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 3.2224e-07 - val_loss: 3.1061e-07\n",
      "Epoch 16/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 3.1544e-07 - val_loss: 3.0415e-07\n",
      "Epoch 17/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 3.0905e-07 - val_loss: 2.9809e-07\n",
      "Epoch 18/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 3.0298e-07 - val_loss: 2.9237e-07\n",
      "Epoch 19/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.9723e-07 - val_loss: 2.8698e-07\n",
      "Epoch 20/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.9173e-07 - val_loss: 2.8185e-07\n",
      "Epoch 21/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.8647e-07 - val_loss: 2.7698e-07\n",
      "Epoch 22/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.8146e-07 - val_loss: 2.7237e-07\n",
      "Epoch 23/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.7665e-07 - val_loss: 2.6792e-07\n",
      "Epoch 24/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.7203e-07 - val_loss: 2.6366e-07\n",
      "Epoch 25/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.6758e-07 - val_loss: 2.5955e-07\n",
      "Epoch 26/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.6330e-07 - val_loss: 2.5558e-07\n",
      "Epoch 27/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.5916e-07 - val_loss: 2.5179e-07\n",
      "Epoch 28/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.5515e-07 - val_loss: 2.4815e-07\n",
      "Epoch 29/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.5128e-07 - val_loss: 2.4466e-07\n",
      "Epoch 30/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.4752e-07 - val_loss: 2.4131e-07\n",
      "Epoch 31/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.4388e-07 - val_loss: 2.3809e-07\n",
      "Epoch 32/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.4037e-07 - val_loss: 2.3496e-07\n",
      "Epoch 33/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.3697e-07 - val_loss: 2.3194e-07\n",
      "Epoch 34/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.3365e-07 - val_loss: 2.2901e-07\n",
      "Epoch 35/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.3044e-07 - val_loss: 2.2620e-07\n",
      "Epoch 36/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.2733e-07 - val_loss: 2.2348e-07\n",
      "Epoch 37/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.2431e-07 - val_loss: 2.2086e-07\n",
      "Epoch 38/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.2138e-07 - val_loss: 2.1831e-07\n",
      "Epoch 39/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.1854e-07 - val_loss: 2.1584e-07\n",
      "Epoch 40/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.1579e-07 - val_loss: 2.1345e-07\n",
      "Epoch 41/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.1311e-07 - val_loss: 2.1114e-07\n",
      "Epoch 42/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.1051e-07 - val_loss: 2.0888e-07\n",
      "Epoch 43/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.0797e-07 - val_loss: 2.0671e-07\n",
      "Epoch 44/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.0549e-07 - val_loss: 2.0460e-07\n",
      "Epoch 45/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.0307e-07 - val_loss: 2.0255e-07\n",
      "Epoch 46/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2.0071e-07 - val_loss: 2.0054e-07\n",
      "Epoch 47/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 1.9841e-07 - val_loss: 1.9859e-07\n",
      "Epoch 48/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 1.9617e-07 - val_loss: 1.9668e-07\n",
      "Epoch 49/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.9397e-07 - val_loss: 1.9483e-07\n",
      "Epoch 50/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 1.9182e-07 - val_loss: 1.9302e-07\n",
      "Epoch 51/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 1.8972e-07 - val_loss: 1.9126e-07\n",
      "Epoch 52/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 1.8767e-07 - val_loss: 1.8955e-07\n",
      "Epoch 53/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 1.8568e-07 - val_loss: 1.8789e-07\n",
      "Epoch 54/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 1.8374e-07 - val_loss: 1.8628e-07\n",
      "Epoch 55/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 1.8184e-07 - val_loss: 1.8472e-07\n",
      "Epoch 56/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.7999e-07 - val_loss: 1.8320e-07\n",
      "Epoch 57/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.7819e-07 - val_loss: 1.8171e-07\n",
      "Epoch 58/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.7642e-07 - val_loss: 1.8027e-07\n",
      "Epoch 59/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.7470e-07 - val_loss: 1.7885e-07\n",
      "Epoch 60/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.7302e-07 - val_loss: 1.7747e-07\n",
      "Epoch 61/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.7136e-07 - val_loss: 1.7614e-07\n",
      "Epoch 62/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.6974e-07 - val_loss: 1.7484e-07\n",
      "Epoch 63/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.6816e-07 - val_loss: 1.7357e-07\n",
      "Epoch 64/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.6661e-07 - val_loss: 1.7234e-07\n",
      "Epoch 65/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.6509e-07 - val_loss: 1.7112e-07\n",
      "Epoch 66/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.6360e-07 - val_loss: 1.6993e-07\n",
      "Epoch 67/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.6214e-07 - val_loss: 1.6877e-07\n",
      "Epoch 68/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.6071e-07 - val_loss: 1.6765e-07\n",
      "Epoch 69/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.5931e-07 - val_loss: 1.6655e-07\n",
      "Epoch 70/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.5792e-07 - val_loss: 1.6548e-07\n",
      "Epoch 71/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.5657e-07 - val_loss: 1.6443e-07\n",
      "Epoch 72/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.5524e-07 - val_loss: 1.6342e-07\n",
      "Epoch 73/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.5393e-07 - val_loss: 1.6243e-07\n",
      "Epoch 74/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.5265e-07 - val_loss: 1.6147e-07\n",
      "Epoch 75/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.5139e-07 - val_loss: 1.6052e-07\n",
      "Epoch 76/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.5016e-07 - val_loss: 1.5961e-07\n",
      "Epoch 77/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.4896e-07 - val_loss: 1.5872e-07\n",
      "Epoch 78/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.4777e-07 - val_loss: 1.5786e-07\n",
      "Epoch 79/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.4661e-07 - val_loss: 1.5703e-07\n",
      "Epoch 80/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.4548e-07 - val_loss: 1.5621e-07\n",
      "Epoch 81/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.4436e-07 - val_loss: 1.5543e-07\n",
      "Epoch 82/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.4327e-07 - val_loss: 1.5465e-07\n",
      "Epoch 83/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.4220e-07 - val_loss: 1.5390e-07\n",
      "Epoch 84/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.4115e-07 - val_loss: 1.5316e-07\n",
      "Epoch 85/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.4011e-07 - val_loss: 1.5244e-07\n",
      "Epoch 86/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.3910e-07 - val_loss: 1.5174e-07\n",
      "Epoch 87/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.3810e-07 - val_loss: 1.5106e-07\n",
      "Epoch 88/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.3713e-07 - val_loss: 1.5040e-07\n",
      "Epoch 89/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.3616e-07 - val_loss: 1.4975e-07\n",
      "Epoch 90/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.3521e-07 - val_loss: 1.4911e-07\n",
      "Epoch 91/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.3428e-07 - val_loss: 1.4849e-07\n",
      "Epoch 92/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.3336e-07 - val_loss: 1.4788e-07\n",
      "Epoch 93/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.3246e-07 - val_loss: 1.4729e-07\n",
      "Epoch 94/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.3157e-07 - val_loss: 1.4672e-07\n",
      "Epoch 95/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.3070e-07 - val_loss: 1.4616e-07\n",
      "Epoch 96/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.2985e-07 - val_loss: 1.4562e-07\n",
      "Epoch 97/97\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.2900e-07 - val_loss: 1.4508e-07\n",
      "\n",
      "Validation focal loss (last epoch): 1.4508013634895178e-07\n",
      "Macro F1 @0.5: 0.1679754658864425\n",
      "Micro F1 @0.5: 0.4434389140271493\n",
      "\n",
      "Per-label classification report:\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "              TWF       0.00      0.00      0.00         7\n",
      "              HDF       0.32      0.85      0.46        26\n",
      "              PWF       0.45      0.76      0.57        17\n",
      "              OSF       0.27      1.00      0.42        13\n",
      "              RNF       0.00      0.00      0.00         3\n",
      "    joint_PWF_OSF       0.50      0.33      0.40         3\n",
      "    joint_TWF_RNF       0.00      0.00      0.00         1\n",
      "    joint_HDF_PWF       0.00      0.00      0.00         0\n",
      "    joint_HDF_OSF       0.00      0.00      0.00         0\n",
      "    joint_TWF_OSF       0.00      0.00      0.00         0\n",
      "joint_TWF_PWF_OSF       0.00      0.00      0.00         0\n",
      "\n",
      "        micro avg       0.32      0.70      0.44        70\n",
      "        macro avg       0.14      0.27      0.17        70\n",
      "     weighted avg       0.30      0.70      0.40        70\n",
      "      samples avg       0.02      0.02      0.02        70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Build model as you already did, using engineered features ---\n",
    "hidden_layer_sizes = [\n",
    "    best_params['units_l0'],\n",
    "    best_params['units_l1'],\n",
    "    best_params['units_l2'],\n",
    "    best_params['units_l3'],\n",
    "    best_params['units_l4'],\n",
    "]\n",
    "model = build_model(hidden_layer_sizes=hidden_layer_sizes)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=best_params['lr'],\n",
    "    beta_1=best_params['beta_1'],\n",
    "    beta_2=best_params['beta_2'],\n",
    "    epsilon=best_params['epsilon'],\n",
    ")\n",
    "\n",
    "# >>> Binary Focal Loss (simple version) <<<\n",
    "bfl_loss = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "    gamma=15.0,\n",
    "    alpha=.96,\n",
    "    apply_class_balancing=True,\n",
    "    from_logits=False,\n",
    "    reduction=\"sum_over_batch_size\"\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=bfl_loss,\n",
    "    metrics=[]   # we'll compute F1 with sklearn like before\n",
    ")\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    to_input_list(train_df),\n",
    "    y_train,\n",
    "    validation_data=(to_input_list(val_df), y_val),\n",
    "    epochs=int(best_params['epochs']),\n",
    "    batch_size=8,\n",
    "    callbacks=[es],\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "val_probs = model.predict(to_input_list(val_df), verbose=0)\n",
    "val_pred  = (val_probs >= 0.5).astype(int)\n",
    "\n",
    "macro_f1 = f1_score(y_val, val_pred, average='macro', zero_division=0)\n",
    "micro_f1 = f1_score(y_val, val_pred, average='micro', zero_division=0)\n",
    "\n",
    "print(\"\\nValidation focal loss (last epoch):\", history.history['val_loss'][-1])\n",
    "print(\"Macro F1 @0.5:\", macro_f1)\n",
    "print(\"Micro F1 @0.5:\", micro_f1)\n",
    "\n",
    "print(\"\\nPer-label classification report:\\n\")\n",
    "print(classification_report(y_val, val_pred, target_names=targets, zero_division=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering is showing signes of improvement in performance. Transferring to experimentation space for optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
